{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6toAdIV-BjZr"
      },
      "source": [
        "# Handling multiple sequences (PyTorch)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "d4gCtwySBuoW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E_n6FH2zBjZt"
      },
      "source": [
        "Install the Transformers, Datasets, and Evaluate libraries to run this notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7SDlKe7gBjZu"
      },
      "outputs": [],
      "source": [
        "!pip install datasets evaluate transformers[sentencepiece]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K-53oDWFBjZv",
        "outputId": "2f8a1d69-a3f9-49c2-f2a2-036989d79320"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "IndexError: Dimension out of range (expected to be in range of [-1, 0], but got 1)"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(checkpoint)\n",
        "\n",
        "sequence = \"I've been waiting for a HuggingFace course my whole life.\"\n",
        "\n",
        "tokens = tokenizer.tokenize(sequence)\n",
        "ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "input_ids = torch.tensor(ids)\n",
        "# This line will fail.\n",
        "model(input_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Goe3Da1XBjZv",
        "outputId": "b45688b6-9bc6-4a2c-f140-f638cf9e30b0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[  101,  1045,  1005,  2310,  2042,  3403,  2005,  1037, 17662, 12172,\n",
              "          2607,  2026,  2878,  2166,  1012,   102]])"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenized_inputs = tokenizer(sequence, return_tensors=\"pt\")\n",
        "print(tokenized_inputs[\"input_ids\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "wi3kx_ZsBjZw",
        "outputId": "408aa90f-a77c-4319-898b-f93a9c201251",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input IDs: tensor([[ 1045,  1005,  2310,  2042,  3403,  2005,  1037, 17662, 12172,  2607,\n",
            "          2026,  2878,  2166,  1012]])\n",
            "Logits: tensor([[-2.7276,  2.8789]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(checkpoint)\n",
        "\n",
        "sequence = \"I've been waiting for a HuggingFace course my whole life.\"\n",
        "\n",
        "tokens = tokenizer.tokenize(sequence)\n",
        "ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "\n",
        "input_ids = torch.tensor([ids])\n",
        "print(\"Input IDs:\", input_ids)\n",
        "\n",
        "output = model(input_ids)\n",
        "print(\"Logits:\", output.logits)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sequence1 = \"I've been waiting for a HuggingFace course my whole life.\"\n",
        "sequence2 = \"I hate this so much!\"\n",
        "tokens1 = tokenizer.tokenize(sequence1)\n",
        "ids1 = tokenizer.convert_tokens_to_ids(tokens1)\n",
        "tokens2 = tokenizer.tokenize(sequence2)\n",
        "ids2 = tokenizer.convert_tokens_to_ids(tokens2)\n",
        "input_ids1 = torch.tensor([ids1])\n",
        "input_ids2 = torch.tensor([ids2])\n",
        "print(\"Sequence 1 input IDs:\", input_ids1)\n",
        "print(\"Sequence 2 input IDs:\", input_ids2)\n",
        "output1 = model(input_ids1)\n",
        "output2 = model(input_ids2)\n",
        "print(\"Sequence 1 output:\", output1.logits)\n",
        "print(\"Sequence 2 output:\", output2.logits)"
      ],
      "metadata": {
        "id": "iMgsDuRDB0TC",
        "outputId": "8014ba88-35d3-4493-be5a-5750fe25d10b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sequence 1 input IDs: tensor([[ 1045,  1005,  2310,  2042,  3403,  2005,  1037, 17662, 12172,  2607,\n",
            "          2026,  2878,  2166,  1012]])\n",
            "Sequence 2 input IDs: tensor([[1045, 5223, 2023, 2061, 2172,  999]])\n",
            "Sequence 1 output: tensor([[-2.7276,  2.8789]], grad_fn=<AddmmBackward0>)\n",
            "Sequence 2 output: tensor([[ 3.1931, -2.6685]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batched_ids = [\n",
        "    [ 1045,  1005,  2310,  2042,  3403,  2005,  1037, 17662, 12172,  2607,\n",
        "          2026,  2878,  2166,  1012],\n",
        "    [1045, 5223, 2023, 2061, 2172,  999,tokenizer.pad_token_id,tokenizer.pad_token_id,tokenizer.pad_token_id,tokenizer.pad_token_id\n",
        "     ,tokenizer.pad_token_id,tokenizer.pad_token_id,tokenizer.pad_token_id,tokenizer.pad_token_id]\n",
        "]\n",
        "attention_mask = [\n",
        "    [1,1,1,1,1,1,1,1,1,1,1,1,1,1],\n",
        "    [1,1,1,1,1,1,0,0,0,0,0,0,0,0]\n",
        "]\n",
        "print(model(torch.tensor(batched_ids),attention_mask=torch.tensor(attention_mask)).logits)"
      ],
      "metadata": {
        "id": "gAFdHXMHChbD",
        "outputId": "c205ac30-2d47-43d7-dab1-c80be32cec47",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-2.7276,  2.8789],\n",
            "        [ 3.1931, -2.6685]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CsPNktUyBjZw"
      },
      "outputs": [],
      "source": [
        "batched_ids = [\n",
        "    [200, 200, 200],\n",
        "    [200, 200]\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KLm22erxBjZw"
      },
      "outputs": [],
      "source": [
        "padding_id = 100\n",
        "\n",
        "batched_ids = [\n",
        "    [200, 200, 200],\n",
        "    [200, 200, padding_id],\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BVWuSxm7BjZw",
        "outputId": "c683f0fa-045d-40e2-b577-850ae01a6613"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 1.5694, -1.3895]], grad_fn=<AddmmBackward>)\n",
              "tensor([[ 0.5803, -0.4125]], grad_fn=<AddmmBackward>)\n",
              "tensor([[ 1.5694, -1.3895],\n",
              "        [ 1.3373, -1.2163]], grad_fn=<AddmmBackward>)"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = AutoModelForSequenceClassification.from_pretrained(checkpoint)\n",
        "\n",
        "sequence1_ids = [[200, 200, 200]]\n",
        "sequence2_ids = [[200, 200]]\n",
        "batched_ids = [\n",
        "    [200, 200, 200],\n",
        "    [200, 200, tokenizer.pad_token_id],\n",
        "]\n",
        "\n",
        "print(model(torch.tensor(sequence1_ids)).logits)\n",
        "print(model(torch.tensor(sequence2_ids)).logits)\n",
        "print(model(torch.tensor(batched_ids)).logits)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nj9yGNw4BjZx",
        "outputId": "d1a52fc7-3e49-45fa-f3d0-0515944fc722"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 1.5694, -1.3895],\n",
              "        [ 0.5803, -0.4125]], grad_fn=<AddmmBackward>)"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "batched_ids = [\n",
        "    [200, 200, 200],\n",
        "    [200, 200, tokenizer.pad_token_id],\n",
        "]\n",
        "\n",
        "attention_mask = [\n",
        "    [1, 1, 1],\n",
        "    [1, 1, 0],\n",
        "]\n",
        "\n",
        "outputs = model(torch.tensor(batched_ids), attention_mask=torch.tensor(attention_mask))\n",
        "print(outputs.logits)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bx2FzaYpBjZx"
      },
      "outputs": [],
      "source": [
        "sequence = sequence[:max_sequence_length]"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Handling multiple sequences (PyTorch)",
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}